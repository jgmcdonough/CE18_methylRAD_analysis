{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9fbce3a-245f-41eb-8233-9d7df692d304",
   "metadata": {},
   "source": [
    "bash script for initial fastqc on raw reads - important to specify an output directory (with -o flag)\n",
    "\n",
    "sarah said any job under 24 hours is still considered a short job, so good to just have that be your default so things don't run out of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c39740-ad02-4a1e-a02f-09311eaba317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "\n",
    "conda config --add channels defaults\n",
    "conda config --add channels bioconda\n",
    "conda config --add channels conda-forge\n",
    "conda config --set channel_priority strict\n",
    "\n",
    "conda create --name myenv python=3.11\n",
    "conda activate myenv\n",
    "\n",
    "\n",
    "conda install fastqc\n",
    "\n",
    "\n",
    "fastqc -o /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/fastqc /project/pi_sarah_gignouxwolfsohn_uml_edu/Raw_sequences/methyl_raw/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea4895c-4d8c-4f29-b504-e43509b9e76d",
   "metadata": {},
   "source": [
    "easier to look and interpret the fastqc results with multiqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a0369-a2d1-4ab4-a387-d042029b43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "\n",
    "conda config --add channels defaults\n",
    "conda config --add channels bioconda\n",
    "conda config --add channels conda-forge\n",
    "conda config --set channel_priority strict\n",
    "\n",
    "conda create --name myenv python=3.11\n",
    "conda activate myenv\n",
    "\n",
    "conda install multiqc\n",
    "\n",
    "\n",
    "multiqc -o /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/multiqc /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/fastqc/fastqc_html/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013707b-cd4c-4b82-a8cd-8f416c5e993e",
   "metadata": {},
   "source": [
    "results from this is an html link - have to download it, then open it on a browser\n",
    "\n",
    "assuming everything looks okay (or good enough, quality won't be there yet) - trim reads - I used trim-galore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10769de9-3959-40aa-87c2-10e8440bcf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "#-----------------modules-----------------#\n",
    "module load miniconda/4.11.0\n",
    "\n",
    "# have to make sure you have cutadapt AND fastqc installed before trim_galore\n",
    "\n",
    "conda create -n cutadaptenv cutadapt\n",
    "conda activate cutadaptenv\n",
    "\n",
    "conda install trim-galore\n",
    "\n",
    "#---------------change wd----------------#\n",
    "\n",
    "cd project/pi_sarah_gignouxwolfsohn_uml_edu/Raw_sequences/methyl_raw/\n",
    "\n",
    "#-----------------commands----------------#\n",
    "\n",
    "for f in $(ls project/pi_sarah_gignouxwolfsohn_uml_edu/Raw_sequences/methyl_raw/ | sed 's/[^-]*$//'); \n",
    "do \n",
    "    trim_galore -q 20 --phred33 --length 20 --max_length 40 --paired \"$f\"CV_R1_001.fastq.gz \"$f\"CV_R2_001.fastq.gz --output_dir project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/;\n",
    "done\n",
    "\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e714d4-b15f-4dec-ac3c-95e8bff9ea86",
   "metadata": {},
   "source": [
    "phred score min of 33, min length 20bp, max length 40bp, paired-ends, didn't specify an adapter to remove so the default is auto-detect - and need to specify output directory\n",
    "\n",
    "then fastqc and multiqc on these filtered and trimmed samples and compared - made sure quality checks were better\n",
    "\n",
    "for mapping, tried hisat2 but was getting low alignment rates - sticking with bowtie2 instead - get alignment rates between ~85-90%\n",
    "\n",
    "Submitted GenBank assembly GCA_002022765.4 https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_002022765.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6087c50-6eac-459a-9299-cc05077b8484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load bowtie2/2.4.2\n",
    "\n",
    "#------------build index------------------#\n",
    "\n",
    "# This line creates the index in the current directory\n",
    "bowtie2-build GCA_002022765.4_C_virginica-3.0_genomic.fna reference_index\n",
    "\n",
    "# Set the paths and directories\n",
    "reference_index=\"reference_index\"\n",
    "\n",
    "# Directory containing your input FASTQ files\n",
    "input_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files\"\n",
    "\n",
    "# Output directory for Bowtie2 results\n",
    "output_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/filtered_alignment_output\"\n",
    "\n",
    "# Create an array with your sample names\n",
    "sample_names=( \"2018--BBB-WBO-B21-CV\"\n",
    "\"2018--BBB-WBV-B70-CV\"\n",
    "\"2018--BBO-BBO-B16-CV\"\n",
    "\"2018--BBO-BBY-B27-CV\"\n",
    "\"2018--BBO-WBO-B16-CV\"\n",
    "\"2018--BBO-WBV-B64-CV\"\n",
    "\"2018--BBR-BBB-B50-CV\"\n",
    "\"2018--BBR-BBG-B38-CV\"\n",
    "\"2018--BBR-BBY-B26-CV\"\n",
    "\"2018--BBY-WBG-B42-CV\"\n",
    "\"2018--BPO-BPO-O16-CV\"\n",
    "\"2018--BPR-BPG-O38-CV\"\n",
    "\"2018--BPR-BPR-O02-CV\"\n",
    "\"2018--BPY-BPG-O42-CV\"\n",
    "\"2018--BPY-BPY-O29-CV\"\n",
    "\"2018--WBB-WBV-W69-CV\"\n",
    "\"2018--WBG-BBB-W56-CV\"\n",
    "\"2018--WBG-WBG-W44-CV\"\n",
    "\"2018--WBO-BBR-W03-CV\"\n",
    "\"2018--WBO-WBV-W64-CV\"\n",
    "\"2018--WBR-BBY-W25-CV\"\n",
    "\"2018--WBV-WBO-W23-CV\"\n",
    "\"2018--WBV-WBR-W12-CV\"\n",
    "\"2018--WBY-BBV-W65-CV\"\n",
    "\"2018--WBY-BBY-W30-CV\"\n",
    "\"2018--WPB-BPG-G45-CV\"\n",
    "\"2018--WPO-BPO-G16-CV\"\n",
    "\"2018--WPO-BPY-G28-CV\"\n",
    "\"2018--WPR-BPY-G25-CV\"\n",
    "\"2018--WPV-BPR-G11-CV\" )\n",
    "\n",
    "\n",
    "# Loop through the sample names\n",
    "for sample_name in \"${sample_names[@]}\"; do\n",
    "    # Construct the file names for R1 and R2\n",
    "    read1=\"${input_dir}/${sample_name}_R1_001_val_1.fq.gz\"\n",
    "    read2=\"${input_dir}/${sample_name}_R2_001_val_2.fq.gz\"\n",
    "\n",
    "    # Output SAM file with full path to the output directory\n",
    "    output_sam=\"${output_dir}/${sample_name}_alignment.sam\"\n",
    "\n",
    "    # Run Bowtie2 for paired-end reads\n",
    "    bowtie2 --very-sensitive --local -x \"${reference_index}\" -1 \"${read1}\" -2 \"${read2}\" -S \"${output_sam}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d23f7-a88f-4d59-9303-b1402cec2283",
   "metadata": {},
   "source": [
    "need to find another way to do the sample names better - more automated - but struggling with getting that part of the code to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ec910-cc7c-497b-a51a-8a6182304e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list to store the matching lines\n",
    "alignment_rate_lines = []\n",
    "\n",
    "# Specify the Slurm output file path\n",
    "slurm_out_file = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/slurm-13167043.out'\n",
    "\n",
    "# Open the Slurm output file and search for lines containing 'overall alignment rate'\n",
    "with open(slurm_out_file, 'r') as file:\n",
    "    for line in file:\n",
    "        if 'overall alignment rate' in line:\n",
    "            alignment_rate_lines.append(line.strip())\n",
    "\n",
    "# Print the extracted lines or perform further processing\n",
    "for line in alignment_rate_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe53b0-6b4d-4ebb-b651-1144d8304009",
   "metadata": {},
   "source": [
    "finding the overall alignment rates for each sample from the slurm.out file\n",
    "\n",
    "88.69% overall alignment rate\n",
    "87.89% overall alignment rate\n",
    "88.79% overall alignment rate\n",
    "88.51% overall alignment rate\n",
    "88.17% overall alignment rate\n",
    "88.19% overall alignment rate\n",
    "88.64% overall alignment rate\n",
    "88.59% overall alignment rate\n",
    "88.58% overall alignment rate\n",
    "89.15% overall alignment rate\n",
    "88.38% overall alignment rate\n",
    "88.77% overall alignment rate\n",
    "88.71% overall alignment rate\n",
    "88.28% overall alignment rate\n",
    "88.79% overall alignment rate\n",
    "87.70% overall alignment rate\n",
    "88.44% overall alignment rate\n",
    "88.46% overall alignment rate\n",
    "87.39% overall alignment rate\n",
    "87.72% overall alignment rate\n",
    "88.25% overall alignment rate\n",
    "88.66% overall alignment rate\n",
    "88.38% overall alignment rate\n",
    "88.12% overall alignment rate\n",
    "88.34% overall alignment rate\n",
    "87.25% overall alignment rate\n",
    "88.63% overall alignment rate\n",
    "87.33% overall alignment rate\n",
    "88.85% overall alignment rate\n",
    "88.54% overall alignment rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435c5686-2c23-4887-84ec-88691867d280",
   "metadata": {},
   "source": [
    "now need to convert SAM files to BAM files and sort those for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d010c-bb49-4d8f-8abd-f20fb3ded067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/SAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools view -b \"$f\"CV_alignment.sam > \"$f\"CV_alignment.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a533b08-b0ed-495e-b4aa-53abd7593902",
   "metadata": {},
   "source": [
    "now have BAM files, and needed to move the BAM files to the right directory - now sorting BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281c5464-5cd3-4ed3-baf7-25fb87124097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/BAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools sort \"$f\"CV_alignment.bam -o \"$f\"CV_sorted.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fa7085-9b1a-4bf6-9f6c-5aeebf90031b",
   "metadata": {},
   "source": [
    "now have sorted BAM files - need to run picard tool and mark optical duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026bdf7-077d-4506-a066-3a78dda9ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# ----------------Parameters---------------------- #\n",
    "#\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "\n",
    "conda create -n my-java-environment -c conda-forge openjdk=17\n",
    "conda activate my-java-environment\n",
    "\n",
    "\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "# Define the path to the Picard JAR file\n",
    "PICARD_JAR=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/CE_MethylRAD_analysis_2018/picard.jar\"  # Replace with the actual path\n",
    "\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/sorted_BAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "java -jar \"$PICARD_JAR\" MarkDuplicates \\\n",
    "      I=\"$f\"CV_sorted.bam \\\n",
    "      O=\"$f\"marked_duplicates.bam \\\n",
    "      M=\"$f\"marked_dup_metrics.txt;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980f1a61-4aed-4c28-abbc-dd366f742ce4",
   "metadata": {},
   "source": [
    "so i checked sarah's code - she made notes that she should've aligned to the RefSeq assembly since it is annotated - so I'm going to go back through the assembly and picard duplicate steps with the RefSeq file\n",
    "\n",
    "NCBI RefSeq assembly: GCF_002022765.2 https://www.ncbi.nlm.nih.gov/genome/annotation_euk/Crassostrea_virginica/100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd90a30-5025-4e9a-bb3b-86d0a6b0753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load bowtie2/2.4.2\n",
    "\n",
    "#------------build index------------------#\n",
    "\n",
    "# This line creates the index in the current directory\n",
    "bowtie2-build GCF_002022765.2_C_virginica-3.0_genomic.fna reference_index\n",
    "\n",
    "# Set the paths and directories\n",
    "reference_index=\"reference_index\"\n",
    "\n",
    "# Directory containing your input FASTQ files\n",
    "input_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files\"\n",
    "\n",
    "# Output directory for Bowtie2 results\n",
    "output_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2/filtered_alignment_output\"\n",
    "\n",
    "# Create an array with your sample names\n",
    "sample_names=( \"2018--BBB-WBO-B21-CV\"\n",
    "\"2018--BBB-WBV-B70-CV\"\n",
    "\"2018--BBO-BBO-B16-CV\"\n",
    "\"2018--BBO-BBY-B27-CV\"\n",
    "\"2018--BBO-WBO-B16-CV\"\n",
    "\"2018--BBO-WBV-B64-CV\"\n",
    "\"2018--BBR-BBB-B50-CV\"\n",
    "\"2018--BBR-BBG-B38-CV\"\n",
    "\"2018--BBR-BBY-B26-CV\"\n",
    "\"2018--BBY-WBG-B42-CV\"\n",
    "\"2018--BPO-BPO-O16-CV\"\n",
    "\"2018--BPR-BPG-O38-CV\"\n",
    "\"2018--BPR-BPR-O02-CV\"\n",
    "\"2018--BPY-BPG-O42-CV\"\n",
    "\"2018--BPY-BPY-O29-CV\"\n",
    "\"2018--WBB-WBV-W69-CV\"\n",
    "\"2018--WBG-BBB-W56-CV\"\n",
    "\"2018--WBG-WBG-W44-CV\"\n",
    "\"2018--WBO-BBR-W03-CV\"\n",
    "\"2018--WBO-WBV-W64-CV\"\n",
    "\"2018--WBR-BBY-W25-CV\"\n",
    "\"2018--WBV-WBO-W23-CV\"\n",
    "\"2018--WBV-WBR-W12-CV\"\n",
    "\"2018--WBY-BBV-W65-CV\"\n",
    "\"2018--WBY-BBY-W30-CV\"\n",
    "\"2018--WPB-BPG-G45-CV\"\n",
    "\"2018--WPO-BPO-G16-CV\"\n",
    "\"2018--WPO-BPY-G28-CV\"\n",
    "\"2018--WPR-BPY-G25-CV\"\n",
    "\"2018--WPV-BPR-G11-CV\" )\n",
    "\n",
    "\n",
    "# Loop through the sample names\n",
    "for sample_name in \"${sample_names[@]}\"; do\n",
    "    # Construct the file names for R1 and R2\n",
    "    read1=\"${input_dir}/${sample_name}_R1_001_val_1.fq.gz\"\n",
    "    read2=\"${input_dir}/${sample_name}_R2_001_val_2.fq.gz\"\n",
    "\n",
    "    # Output SAM file with full path to the output directory\n",
    "    output_sam=\"${output_dir}/${sample_name}_alignment.sam\"\n",
    "\n",
    "    # Run Bowtie2 for paired-end reads\n",
    "    bowtie2 --very-sensitive --local -x \"${reference_index}\" -1 \"${read1}\" -2 \"${read2}\" -S \"${output_sam}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "695dd3f7-b91d-4e42-90a2-259edfa4bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.69% overall alignment rate\n",
      "87.89% overall alignment rate\n",
      "88.79% overall alignment rate\n",
      "88.51% overall alignment rate\n",
      "88.17% overall alignment rate\n",
      "88.19% overall alignment rate\n",
      "88.64% overall alignment rate\n",
      "88.59% overall alignment rate\n",
      "88.58% overall alignment rate\n",
      "89.15% overall alignment rate\n",
      "88.38% overall alignment rate\n",
      "88.77% overall alignment rate\n",
      "88.71% overall alignment rate\n",
      "88.29% overall alignment rate\n",
      "88.79% overall alignment rate\n",
      "87.70% overall alignment rate\n",
      "88.44% overall alignment rate\n",
      "88.46% overall alignment rate\n",
      "87.39% overall alignment rate\n",
      "87.72% overall alignment rate\n",
      "88.25% overall alignment rate\n",
      "88.66% overall alignment rate\n",
      "88.38% overall alignment rate\n",
      "88.12% overall alignment rate\n",
      "88.34% overall alignment rate\n",
      "87.25% overall alignment rate\n",
      "88.63% overall alignment rate\n",
      "87.33% overall alignment rate\n",
      "88.85% overall alignment rate\n",
      "88.54% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store the matching lines\n",
    "alignment_rate_lines = []\n",
    "\n",
    "# Specify the Slurm output file path\n",
    "slurm_out_file = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/slurm-13289020.out'\n",
    "\n",
    "# Open the Slurm output file and search for lines containing 'overall alignment rate'\n",
    "with open(slurm_out_file, 'r') as file:\n",
    "    for line in file:\n",
    "        if 'overall alignment rate' in line:\n",
    "            alignment_rate_lines.append(line.strip())\n",
    "\n",
    "# Print the extracted lines or perform further processing\n",
    "for line in alignment_rate_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6c064a-ce3f-4bcb-9d0a-cbf693b1b001",
   "metadata": {},
   "source": [
    "overall alignment rates:\n",
    "88.69% overall alignment rate 87.89% overall alignment rate 88.79% overall alignment rate 88.51% overall alignment rate 88.17% overall alignment rate 88.19% overall alignment rate 88.64% overall alignment rate 88.59% overall alignment rate 88.58% overall alignment rate 89.15% overall alignment rate 88.38% overall alignment rate 88.77% overall alignment rate 88.71% overall alignment rate 88.29% overall alignment rate 88.79% overall alignment rate 87.70% overall alignment rate 88.44% overall alignment rate 88.46% overall alignment rate 87.39% overall alignment rate 87.72% overall alignment rate 88.25% overall alignment rate 88.66% overall alignment rate 88.38% overall alignment rate 88.12% overall alignment rate 88.34% overall alignment rate 87.25% overall alignment rate 88.63% overall alignment rate 87.33% overall alignment rate 88.85% overall alignment rate 88.54% overall alignment rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd18516-3aef-4774-85cb-8b3600a25956",
   "metadata": {},
   "source": [
    "converting SAM to BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad254a-5ee6-441a-9fa0-983fda517171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/SAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools view -b \"$f\"CV_alignment.sam > \"$f\"CV_alignment.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9c434-9b64-425d-8266-6fc5aea01657",
   "metadata": {},
   "source": [
    "sorting BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d41493-951b-4cbe-8d25-ec7d81f3a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/BAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools sort \"$f\"CV_alignment.bam -o \"$f\"CV_sorted.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ddc5f-afc3-40a2-90c7-3a5e3b6039b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "now using picard to mark duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05674b7c-95c0-4ac0-87f8-3be10bbd7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# ----------------Parameters---------------------- #\n",
    "#\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "#\n",
    "conda create -n my-java-environment -c conda-forge openjdk=17\n",
    "conda activate my-java-environment\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "# Define the path to the Picard JAR file\n",
    "PICARD_JAR=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/CE_MethylRAD_analysis_2018/picard.jar\"  # Replace with the actual path\n",
    "\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/sorted_BAM_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "java -jar \"$PICARD_JAR\" MarkDuplicates \\\n",
    "      I=\"$f\"CV_sorted.bam \\\n",
    "      O=\"$f\"marked_duplicates.bam \\\n",
    "      M=\"$f\"marked_dup_metrics.txt;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bcc20e-1274-4ec1-adf9-928493aa5711",
   "metadata": {},
   "source": [
    "to use bedtools multicov (reports the count of alignments from multiple position-sorted and indexed BAM files that overlap intervals in a BED file)\n",
    "\n",
    "first need to index BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7b78f-24e3-4762-ae0c-0cc52d3f5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 1:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/sorted_BAM_files/*_sorted.bam); \n",
    "do \n",
    "samtools index -b \"$f\" \"$f\".bai;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b4522-7c44-491b-9507-297abddab7ce",
   "metadata": {},
   "source": [
    "htseq-counts to find the number of reads that align to features according to the gtf file from NCBI - output goes into txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600b3e3-b9ef-44c9-bc50-fed800dc9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "pip install HTseq\n",
    "# ----------------Your Commands------------------- #\n",
    "\n",
    "htseq-count -r pos -f bam /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/sorted_BAM_files/*_sorted.bam /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/genomic.gtf >counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12c01c-3dd7-43d3-9434-9d604ddca06f",
   "metadata": {},
   "source": [
    "So - in CV_CE18_pipeline_counts.ipynb, went through and checked how many reads actually have a methyl group somewhere in the sequence - found about 50-70% of reads have that pattern for each sample. So now want to go through and filter for only the reads that have that specific pattern - then realign and go through the above pipeline before doing analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665c7049-0069-4c4a-8bea-6d8586d0127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2018--WBO-BBR-W03-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBO-BBR-W03-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBG-B38-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBR-BBG-B38-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBO-BBR-W03-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBO-BBR-W03-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBG-B38-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBR-BBG-B38-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBB-B50-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBR-BBB-B50-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBV-WBO-W23-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBV-WBO-W23-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBB-WBO-B21-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBB-WBO-B21-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBY-B26-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBR-BBY-B26-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPV-BPR-G11-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WPV-BPR-G11-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBY-WBG-B42-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBY-WBG-B42-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBR-BBY-W25-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBR-BBY-W25-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBB-B50-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBR-BBB-B50-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBV-WBO-W23-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBV-WBO-W23-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBB-WBO-B21-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBB-WBO-B21-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBY-B26-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBR-BBY-B26-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBY-WBG-B42-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBY-WBG-B42-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPV-BPR-G11-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WPV-BPR-G11-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBR-BBY-W25-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBR-BBY-W25-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPR-BPG-O38-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BPR-BPG-O38-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-WBO-B16-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBO-WBO-B16-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPB-BPG-G45-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WPB-BPG-G45-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-WBV-B64-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBO-WBV-B64-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPR-BPG-O38-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BPR-BPG-O38-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-WBO-B16-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBO-WBO-B16-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPB-BPG-G45-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WPB-BPG-G45-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-WBV-B64-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBO-WBV-B64-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPO-BPY-G28-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WPO-BPY-G28-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPR-BPR-O02-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BPR-BPR-O02-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPO-BPY-G28-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WPO-BPY-G28-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPR-BPR-O02-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BPR-BPR-O02-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBO-WBV-W64-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBO-WBV-W64-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPR-BPY-G25-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WPR-BPY-G25-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBB-WBV-B70-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBB-WBV-B70-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBG-WBG-W44-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBG-WBG-W44-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPY-BPG-O42-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BPY-BPG-O42-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPR-BPY-G25-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WPR-BPY-G25-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBO-WBV-W64-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBO-WBV-W64-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBG-WBG-W44-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBG-WBG-W44-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBB-WBV-B70-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBB-WBV-B70-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPY-BPG-O42-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BPY-BPG-O42-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBV-WBR-W12-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBV-WBR-W12-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-BBO-B16-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBO-BBO-B16-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBB-WBV-W69-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBB-WBV-W69-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBY-BBY-W30-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBY-BBY-W30-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBV-WBR-W12-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBV-WBR-W12-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-BBO-B16-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBO-BBO-B16-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBB-WBV-W69-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBB-WBV-W69-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBY-BBY-W30-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBY-BBY-W30-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-BBY-B27-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BBO-BBY-B27-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPO-BPO-G16-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WPO-BPO-G16-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPY-BPY-O29-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BPY-BPY-O29-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-BBY-B27-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BBO-BBY-B27-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPO-BPO-G16-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WPO-BPO-G16-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPY-BPY-O29-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BPY-BPY-O29-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBG-BBB-W56-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBG-BBB-W56-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPO-BPO-O16-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--BPO-BPO-O16-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBY-BBV-W65-CV_R2_001_val_2.fq.gz: Reads matching any pattern written to 2018--WBY-BBV-W65-CV_R2_001_val_2.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBG-BBB-W56-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBG-BBB-W56-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPO-BPO-O16-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--BPO-BPO-O16-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBY-BBV-W65-CV_R1_001_val_1.fq.gz: Reads matching any pattern written to 2018--WBY-BBV-W65-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "patterns = [\"CCAGG\", \"CCCGG\", \"CCTGG\", \"CCGG\", \"GGCC\", \"GGACC\", \"GGGCC\", \"GGTCC\"]\n",
    "\n",
    "def write_matching_reads(file_path, output_dir):\n",
    "    output_file = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(file_path))[0]}_matching_reads.fq.gz\")\n",
    "    with gzip.open(file_path, \"rt\") as handle:  # Use gzip.open for compressed files\n",
    "        with gzip.open(output_file, \"wt\") as out_handle:\n",
    "            for record in SeqIO.parse(handle, \"fastq\"):\n",
    "                if any(pattern in str(record.seq) for pattern in patterns):\n",
    "                    SeqIO.write(record, out_handle, \"fastq\")\n",
    "\n",
    "directory_path = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files\"\n",
    "output_directory = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\"\n",
    "\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\"fq.gz\"):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        write_matching_reads(file_path, output_directory)\n",
    "        print(f\"Sample {filename}: Reads matching any pattern written to {os.path.splitext(filename)[0]}_matching_reads.fq.gz in {output_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2d287f-ce92-4896-b59a-c694a11bd9fa",
   "metadata": {},
   "source": [
    "so the above code worked but didn't account for the sequences being paired-end reads, so bowtie2 alignment gives errors because the reads are uneven lenghts - trying to fix the code so that a sequence is kept only if both reads have the sequence pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b690eb5-e451-4ec7-b50b-6308ffd410db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 2018--WBO-BBR-W03-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--WBO-BBR-W03-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBG-B38-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBR-BBG-B38-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBB-B50-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBR-BBB-B50-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBV-WBO-W23-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--WBV-WBO-W23-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBY-WBG-B42-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBY-WBG-B42-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBB-WBO-B21-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBB-WBO-B21-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBR-BBY-B26-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBR-BBY-B26-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WPV-BPR-G11-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--WPV-BPR-G11-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--WBR-BBY-W25-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--WBR-BBY-W25-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BPR-BPG-O38-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BPR-BPG-O38-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n",
      "Sample 2018--BBO-WBO-B16-CV_R1_001_val_1.fq: Paired-end reads matching any pattern written to 2018--BBO-WBO-B16-CV_R1_001_val_1.fq_matching_reads.fq.gz in /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\n"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "patterns = [\"CCAGG\", \"CCCGG\", \"CCTGG\", \"CCGG\", \"GGCC\", \"GGACC\", \"GGGCC\", \"GGTCC\"]\n",
    "\n",
    "def write_matching_reads(file_path1, file_path2, output_dir):\n",
    "    output_file1 = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(file_path1))[0]}_matching_reads.fq.gz\")\n",
    "    output_file2 = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(file_path2))[0]}_matching_reads.fq.gz\")\n",
    "\n",
    "    with gzip.open(file_path1, \"rt\") as handle1, gzip.open(file_path2, \"rt\") as handle2:\n",
    "        with gzip.open(output_file1, \"wt\") as out_handle1, gzip.open(output_file2, \"wt\") as out_handle2:\n",
    "            for record1, record2 in zip(SeqIO.parse(handle1, \"fastq\"), SeqIO.parse(handle2, \"fastq\")):\n",
    "                if any(pattern in str(record1.seq) for pattern in patterns) and any(pattern in str(record2.seq) for pattern in patterns):\n",
    "                    SeqIO.write(record1, out_handle1, \"fastq\")\n",
    "                    SeqIO.write(record2, out_handle2, \"fastq\")\n",
    "\n",
    "directory_path = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files\"\n",
    "output_directory = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "file_list = [filename for filename in os.listdir(directory_path) if filename.endswith(\"_001_val_1.fq.gz\")]\n",
    "\n",
    "# Process paired reads\n",
    "for forward_filename in file_list:\n",
    "    base_name = os.path.splitext(forward_filename)[0]  # Remove the file extension\n",
    "    reverse_filename = forward_filename.replace(\"_R1_001_val_1.fq.gz\", \"_R2_001_val_2.fq.gz\")\n",
    "\n",
    "    forward_file_path = os.path.join(directory_path, forward_filename)\n",
    "    reverse_file_path = os.path.join(directory_path, reverse_filename)\n",
    "\n",
    "    if os.path.exists(reverse_file_path):\n",
    "        write_matching_reads(forward_file_path, reverse_file_path, output_directory)\n",
    "        print(f\"Sample {base_name}: Paired-end reads matching any pattern written to {base_name}_matching_reads.fq.gz in {output_directory}\")\n",
    "    else:\n",
    "        print(f\"Error: Reverse file not found for {forward_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55212fc4-6f37-4836-a40c-589ae3e67961",
   "metadata": {},
   "source": [
    "bowtie2 alignment with methyl reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e1f9e5-cf7e-48e1-8a31-6fc4408d3635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load bowtie2/2.4.2+py3.8.12\n",
    "\n",
    "#------------build index------------------#\n",
    "\n",
    "# This line creates the index in the current directory\n",
    "bowtie2-build /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/GCF_002022765.2_C_virginica-3.0_genomic.fna reference_index\n",
    "\n",
    "# Set the paths and directories\n",
    "reference_index=\"reference_index\"\n",
    "\n",
    "# Directory containing your input FASTQ files\n",
    "input_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/working_seq\"\n",
    "\n",
    "# Output directory for Bowtie2 results\n",
    "output_dir=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2\"\n",
    "\n",
    "# Create an array with your sample names\n",
    "sample_names=( \"2018--BBB-WBO-B21-CV\"\n",
    "\"2018--BBB-WBV-B70-CV\"\n",
    "\"2018--BBO-BBO-B16-CV\"\n",
    "\"2018--BBO-BBY-B27-CV\"\n",
    "\"2018--BBO-WBO-B16-CV\"\n",
    "\"2018--BBO-WBV-B64-CV\"\n",
    "\"2018--BBR-BBB-B50-CV\"\n",
    "\"2018--BBR-BBG-B38-CV\"\n",
    "\"2018--BBR-BBY-B26-CV\"\n",
    "\"2018--BBY-WBG-B42-CV\"\n",
    "\"2018--BPO-BPO-O16-CV\"\n",
    "\"2018--BPR-BPG-O38-CV\"\n",
    "\"2018--BPR-BPR-O02-CV\"\n",
    "\"2018--BPY-BPG-O42-CV\"\n",
    "\"2018--BPY-BPY-O29-CV\"\n",
    "\"2018--WBB-WBV-W69-CV\"\n",
    "\"2018--WBG-BBB-W56-CV\"\n",
    "\"2018--WBG-WBG-W44-CV\"\n",
    "\"2018--WBO-BBR-W03-CV\"\n",
    "\"2018--WBO-WBV-W64-CV\"\n",
    "\"2018--WBR-BBY-W25-CV\"\n",
    "\"2018--WBV-WBO-W23-CV\"\n",
    "\"2018--WBV-WBR-W12-CV\"\n",
    "\"2018--WBY-BBV-W65-CV\"\n",
    "\"2018--WBY-BBY-W30-CV\"\n",
    "\"2018--WPB-BPG-G45-CV\"\n",
    "\"2018--WPO-BPO-G16-CV\"\n",
    "\"2018--WPO-BPY-G28-CV\"\n",
    "\"2018--WPR-BPY-G25-CV\"\n",
    "\"2018--WPV-BPR-G11-CV\" )\n",
    "\n",
    "\n",
    "# Loop through the sample names\n",
    "for sample_name in \"${sample_names[@]}\"; do\n",
    "    # Construct the file names for R1 and R2\n",
    "    read1=\"${input_dir}/${sample_name}_R1_001_val_1.fq_matching_reads.fq.gz\"\n",
    "    read2=\"${input_dir}/${sample_name}_R2_001_val_2.fq_matching_reads.fq.gz\"\n",
    "\n",
    "    # Output SAM file with full path to the output directory\n",
    "    output_sam=\"${output_dir}/${sample_name}_alignment.sam\"\n",
    "\n",
    "    # Run Bowtie2 for paired-end reads\n",
    "    bowtie2 --very-sensitive --local -x \"${reference_index}\" -1 \"${read1}\" -2 \"${read2}\" -S \"${output_sam}\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a94dd4b-ed59-4b6c-a95a-29ea4b6162f5",
   "metadata": {},
   "source": [
    "finding the alignment rates from bowtie2 alignment of the methyl sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa91906-8bdb-42c3-8e0f-c0edbd9e2d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.30% overall alignment rate\n",
      "87.49% overall alignment rate\n",
      "88.30% overall alignment rate\n",
      "88.05% overall alignment rate\n",
      "87.64% overall alignment rate\n",
      "87.94% overall alignment rate\n",
      "88.14% overall alignment rate\n",
      "88.10% overall alignment rate\n",
      "88.04% overall alignment rate\n",
      "88.63% overall alignment rate\n",
      "88.11% overall alignment rate\n",
      "88.21% overall alignment rate\n",
      "88.18% overall alignment rate\n",
      "87.92% overall alignment rate\n",
      "88.18% overall alignment rate\n",
      "87.25% overall alignment rate\n",
      "87.89% overall alignment rate\n",
      "87.81% overall alignment rate\n",
      "87.41% overall alignment rate\n",
      "87.35% overall alignment rate\n",
      "87.89% overall alignment rate\n",
      "88.33% overall alignment rate\n",
      "87.86% overall alignment rate\n",
      "87.61% overall alignment rate\n",
      "87.94% overall alignment rate\n",
      "86.28% overall alignment rate\n",
      "88.06% overall alignment rate\n",
      "87.36% overall alignment rate\n",
      "88.40% overall alignment rate\n",
      "88.35% overall alignment rate\n"
     ]
    }
   ],
   "source": [
    "# Define the list to store the matching lines\n",
    "alignment_rate_lines = []\n",
    "\n",
    "# Specify the Slurm output file path\n",
    "slurm_out_file = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/slurm-14125745.out'\n",
    "# Open the Slurm output file and search for lines containing 'overall alignment rate'\n",
    "with open(slurm_out_file, 'r') as file:\n",
    "    for line in file:\n",
    "        if 'overall alignment rate' in line:\n",
    "            alignment_rate_lines.append(line.strip())\n",
    "\n",
    "# Print the extracted lines or perform further processing\n",
    "for line in alignment_rate_lines:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f75b0-cbe6-4719-91fc-5f8ec5338db5",
   "metadata": {},
   "source": [
    "88.30% overall alignment rate 87.49% overall alignment rate 88.30% overall alignment rate 88.05% overall alignment rate 87.64% overall alignment rate 87.94% overall alignment rate 88.14% overall alignment rate 88.10% overall alignment rate 88.04% overall alignment rate 88.63% overall alignment rate 88.11% overall alignment rate 88.21% overall alignment rate 88.18% overall alignment rate 87.92% overall alignment rate 88.18% overall alignment rate 87.25% overall alignment rate 87.89% overall alignment rate 87.81% overall alignment rate 87.41% overall alignment rate 87.35% overall alignment rate 87.89% overall alignment rate 88.33% overall alignment rate 87.86% overall alignment rate 87.61% overall alignment rate 87.94% overall alignment rate 86.28% overall alignment rate 88.06% overall alignment rate 87.36% overall alignment rate 88.40% overall alignment rate 88.35% overall alignment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a8a37-03d1-4d77-b0e7-5df4bb0af03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "converting SAM files to BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deee066-5f34-497d-866c-cd7fbd40c7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sam_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools view -b \"$f\"CV_alignment.sam > \"$f\"CV_alignment.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa1bb2-a9bd-470a-8c3a-b7b8b266e861",
   "metadata": {},
   "source": [
    "sorting BAM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74cdc0-da1c-47ef-b8b4-c1d337b97a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/bam_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools sort \"$f\"CV_alignment.bam -o \"$f\"CV_sorted.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26597af7-79c8-4f68-b976-735dd3e724f2",
   "metadata": {},
   "source": [
    "using picard tools to mark duplicates\n",
    "\n",
    "for whatever reason, this code works if i do it line by line in command line, but not when I try to submit it as a job and do it remotely - i didn't change anything about the code from before when it worked, so i'm not sure what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5bb0d4-9ab9-4279-98d5-11ee38701282",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# ----------------Parameters---------------------- #\n",
    "#\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "#\n",
    "conda activate my-java-environment\n",
    "\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "# Define the path to the Picard JAR file\n",
    "PICARD_JAR=\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/CE_MethylRAD_analysis_2018/picard.jar\"  # Replace with the actual path\n",
    "\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "java -jar \"$PICARD_JAR\" MarkDuplicates \\\n",
    "      I=\"$f\"CV_sorted.bam \\\n",
    "      O=\"$f\"marked_duplicates.bam \\\n",
    "      M=\"$f\"marked_dup_metrics.txt;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afce631-4862-41a1-b9fd-08ce53a65da4",
   "metadata": {},
   "source": [
    "using htseq-counts to get the counts matrix for the methyl sequences - this is used as the input for DESeq2 - aligning with the gtf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe3da3c-98f6-4a1a-9650-e8f919ceaee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "pip install HTseq\n",
    "# ----------------Your Commands------------------- #\n",
    "\n",
    "htseq-count --additional-attr=gbkey -r pos -f bam /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/*_sorted.bam /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/genomic.gtf >counts.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ded9a8-1cbf-432e-b978-3f0448a8b8fa",
   "metadata": {},
   "source": [
    "trying to replicate Sarah's cov_CV.log script to figure out the features problem\n",
    "\n",
    "indexing bam files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d19ee-f40b-4975-a5df-49775ac6ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/*_sorted.bam); \n",
    "do \n",
    "samtools index -b \"$f\" \"$f\".bai;\n",
    "\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58899f9e-7e96-4d36-9c29-f5dc1fe68081",
   "metadata": {},
   "source": [
    "another script to index bam files - thought i was having problems with the code above but now i'm thinking that's not where my problem is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05cf41-76bf-4264-975a-0c01237e7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "# Input BAM directory\n",
    "bam_directory=\"/path/to/bam/files\"\n",
    "\n",
    "# Output BAI directory\n",
    "bai_directory=\"/path/to/output/bai/files\"\n",
    "\n",
    "# Loop through all BAM files in the input directory\n",
    "for bam_file in \"$bam_directory\"/*.bam; do\n",
    "    # Get the base name of the BAM file without the path and extension\n",
    "    base_name=$(basename \"$bam_file\" .bam)\n",
    "    \n",
    "    # Create the full path for the output BAI file\n",
    "    bai_file=\"$bai_directory/$base_name.bai\"\n",
    "\n",
    "    # Run samtools index to create the BAI file\n",
    "    samtools index -b \"$bam_file\" \"$bai_file\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc59d88-330c-45bb-a189-f3c5a8125581",
   "metadata": {},
   "source": [
    "trying bedtools multicov again but still not working... says 'could not load/find indexes' - think something with the way files were sorted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb90a57-8c5e-4c05-9ed3-03900407404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/bedtools_multicov/cov_CV.log\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load bedtools/2\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "bedtools multicov -D -bams /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/*.bam -bed /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/GCF_002022765.2_C_virginica-3.0_genomic.bed\n",
    "#\n",
    "echo = `date` job $JOB_NAME done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df207152-bf4d-4bd4-9775-511fa572ede8",
   "metadata": {},
   "source": [
    "code from google to convert a gff file to a bed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b282a3-c621-46c8-a575-8dd54d6f8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def gff_to_bed(gff_file):\n",
    "  \"\"\"Converts a GFF file to a BED file.\n",
    "\n",
    "  Args:\n",
    "    gff_file: The path to the GFF file.\n",
    "\n",
    "  Returns:\n",
    "    A pandas DataFrame containing the BED data.\n",
    "  \"\"\"\n",
    "\n",
    "  # Read the GFF file into a pandas DataFrame.\n",
    "  gff_df = pd.read_csv(gff_file, sep=\"\\t\", header=None, names=[\"seqid\", \"source\", \"type\", \"start\", \"end\", \"score\", \"strand\", \"phase\", \"attributes\"])\n",
    "\n",
    "  # Convert the GFF coordinates to BED coordinates.\n",
    "  gff_df[\"start\"] = (gff_df[\"start\"] - 1)\n",
    "\n",
    "  # Filter the DataFrame to only include features that are transcripts.\n",
    "  gff_df = gff_df[gff_df[\"type\"] == \"transcript\"]\n",
    "\n",
    "  # Select the columns that are needed for the BED file.\n",
    "  gff_df = gff_df[[\"seqid\", \"start\", \"end\"]]\n",
    "\n",
    "  # Return the BED DataFrame.\n",
    "  return gff_df\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "gff_file = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/genomic.gff\"\n",
    "bed_file = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/cv_genomic.bed\"\n",
    "\n",
    "# Convert the GFF file to a BED file.\n",
    "bed_df = gff_to_bed(gff_file)\n",
    "\n",
    "# Save the BED file.\n",
    "bed_df.to_csv(bed_file, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f852166-307c-4eea-868e-70e0fa6e8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to integers, removing decimals\n",
    "bed_df['start'] = bed_df['start'].astype(int)\n",
    "bed_df['end'] = bed_df['end'].astype(int)\n",
    "\n",
    "bed_df.to_csv(bed_file, sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9481e81-5f49-4ceb-8b5e-475db28fde5c",
   "metadata": {},
   "source": [
    "trying bedtools multicov again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c9723-0a4c-4713-b17b-4973c9f2a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/bedtools_multicov/cov_CV.log\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load bedtools/2\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "bedtools multicov -D -bams /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/*.bam -bed /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/cv_genomic.bed > coverage_output.txt\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8dbea6-7017-4c36-9106-1b44bb1b33c1",
   "metadata": {},
   "source": [
    "now thinking that i might be having an issue because i sorted by position instead of by name (i think?)\n",
    "\n",
    "so i should go back to samtools sort and sort the files by name (maintains pairing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94106a3e-52aa-4434-af7b-36f87c8fa5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "\n",
    "# ----------------Modules------------------------- #\n",
    "#\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/bam_files/* | sed 's/[^-]*$//'); \n",
    "do \n",
    "samtools sort \"$f\"CV_alignment.bam -o \"$f\"CV_sorted.bam;\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd6b40-8e33-4a14-9744-ea87759bbf12",
   "metadata": {},
   "source": [
    "now wondering if I can just index the sorted bam files but keep them as bam files instead of converting to bai files and seeing if that would fix the error message i get with bedtools multicov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a71a7-364d-4699-ae46-d90f94e3bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load miniconda/4.11.0\n",
    "module load samtools/1.9\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "#\n",
    "for f in $(ls /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/*_sorted.bam); \n",
    "do \n",
    "samtools index -b \"$f\" \"$f\".indexed_bam;\n",
    "\n",
    "done\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6b01d6-888f-4647-8022-f9f3b4dd6b44",
   "metadata": {},
   "source": [
    "bedtools multicov does NOT work on bai files - here's code script from chatGPT to help with troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041e766b-98f4-4157-bfa5-627168c3f096",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2822805407.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    cd /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/\u001b[0m\n\u001b[0m                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# change to working directory\n",
    "cd /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam/\n",
    "# loop through sorted bam files, create index\n",
    "for bam_file in *.bam; do\n",
    "    samtools index \"$bam_file\" \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e8a95-55af-4d74-97bb-b1fe9dd253f3",
   "metadata": {},
   "source": [
    "*sorted BAM files and indexed BAI files must be in the same directory for bedtools multicov to work!!!!*\n",
    "\n",
    "also make sure BED file doesn't have a header - should only be three columns: seqid, start, end that are tab delimited and should only contain integers for start and end (no decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170b8d99-7dc6-4172-a561-cf81aca59d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load bedtools/2\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "cd /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/bowtie2/sorted_bam\n",
    "#\n",
    "bedtools multicov -D -bams *.bam -bed /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/cv_genomic.bed\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6e255-d75b-4505-8c08-0ebe3ca59ece",
   "metadata": {},
   "source": [
    "trying featureCounts to see if we get any other results? bedtools multicov resulted in a *lot* less genes than what Sarah was getting - maybe that's okay though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bb2d7-132b-4a03-83a8-88dcd6c37b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCounts -a /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/genomic.gtf -o counts.txt -p -B -C -M --largestOverlap -F GTF -t gene_id *.bam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4ba42-3f8d-4a95-959c-2c90f613aad5",
   "metadata": {},
   "source": [
    "trying this to see if we can get those other columns from GTF file into bed file for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26b296-6c66-48fd-8efc-4b62347a70c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a BED file (intervals.bed) and a GTF file (annotations.gtf)\n",
    "# First, use bedtools intersect to find overlapping features\n",
    "bedtools intersect -a /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/cv_genomic.bed -b /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/genomic.gtf -wa -wb > intersected.bed\n",
    "\n",
    "# Now, use awk to rearrange the columns and include additional GTF information\n",
    "awk -v OFS='\\t' '{print $1, $2, $3, $4, $8, $9, $10, $11, $12}' intersected.bed > output_with_info.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c95c1a-59ad-4b3e-adf3-9cee7aa69b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#SBATCH -c 4  # Number of Cores per Task\n",
    "#SBATCH --mem=8192  # Requested Memory\n",
    "#SBATCH -p cpu-long  # Partition\n",
    "#SBATCH -t 24:00:00  # Job time limit\n",
    "#SBATCH --mail-type=ALL\n",
    "#SBATCH -o slurm-%j.out  # %j = job ID\n",
    "#\n",
    "# ----------------Modules------------------------- #\n",
    "module load bedtools/2\n",
    "#\n",
    "# ----------------Your Commands------------------- #\n",
    "#\n",
    "echo + `date` job $JOB_NAME started in $QUEUE with jobID=$JOB_ID on $HOSTNAME\n",
    "cd /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/pipeline_work_seq/sorted_bam\n",
    "#\n",
    "bedtools multicov -D -bams *.bam -bed /project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/reference_genomes/output_with_info.bed\n",
    "#\n",
    "echo = `date` job $JOB_NAME done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc06a2c-fe7c-4a12-a703-14e83f83ac95",
   "metadata": {},
   "source": [
    "groves used samtools flagstats - gives summary of stats, helpful to look at for pipeline stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd6232-efe6-4265-89d1-c046030e81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "module load samtools/1.9\n",
    "\n",
    "for file in *.bam; do\n",
    "> echo \"File: $(basename \"$file\")\"\n",
    "> samtools flagstat \"$file\"\n",
    "> echo \"---------------------------\"\n",
    "> done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
