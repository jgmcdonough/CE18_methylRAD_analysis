{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45096cb-0746-4761-84f4-f08cc4c9f798",
   "metadata": {},
   "source": [
    "## Pipeline Counts for methylRAD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41ef22-29c3-4dcc-af96-6cd25a229aae",
   "metadata": {},
   "source": [
    "#### counts of raw reads and trimmed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bfe304-31d2-492a-8115-e64f1f67484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package to move through directories\n",
    "import os\n",
    "# to change directory\n",
    "os.chdir(\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d849e4-a444-4e30-9b76-47b45c3259a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBO-WBO-B16-CV, Raw Reads: 59769484, Trimmed Reads: 9603844, Ratio: 0.1606813938698216\n",
      "Sample: 2018--BPO-BPO-O16-CV, Raw Reads: 17002472, Trimmed Reads: 936764, Ratio: 0.05509575313519117\n",
      "Sample: 2018--WBV-WBO-W23-CV, Raw Reads: 20244836, Trimmed Reads: 2744600, Ratio: 0.13557037458836416\n",
      "Sample: 2018--BPR-BPG-O38-CV, Raw Reads: 38746892, Trimmed Reads: 4390176, Ratio: 0.11330395222409065\n",
      "Sample: 2018--BBO-WBV-B64-CV, Raw Reads: 49958272, Trimmed Reads: 8379816, Ratio: 0.167736306011545\n",
      "Sample: 2018--WBB-WBV-W69-CV, Raw Reads: 41913360, Trimmed Reads: 8547732, Ratio: 0.20393812378678303\n",
      "Sample: 2018--WPO-BPY-G28-CV, Raw Reads: 26339844, Trimmed Reads: 1346688, Ratio: 0.05112740986620878\n",
      "Sample: 2018--WPB-BPG-G45-CV, Raw Reads: 38780388, Trimmed Reads: 4035068, Ratio: 0.10404919104986779\n",
      "Sample: 2018--BBB-WBV-B70-CV, Raw Reads: 47021020, Trimmed Reads: 7920020, Ratio: 0.16843573363572292\n",
      "Sample: 2018--BBB-WBO-B21-CV, Raw Reads: 60015908, Trimmed Reads: 9142520, Ratio: 0.15233494426177807\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# read directories\n",
    "raw_reads_dir = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/Raw_sequences/methyl_raw/\"\n",
    "trimmed_reads_dir = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files/\"\n",
    "\n",
    "# Collect unique sample names from raw reads directory\n",
    "sample_names = set()\n",
    "for filename in os.listdir(raw_reads_dir):\n",
    "    if filename.endswith(\".fastq.gz\"):\n",
    "        sample_name = filename.split(\"_\")[0]\n",
    "        sample_names.add(sample_name)\n",
    "\n",
    "counts_df = {}\n",
    "# Count reads for each unique sample\n",
    "for sample in sample_names:\n",
    "    trim_filename = f\"{trimmed_reads_dir}{sample}_R1_001_val_1.fq.gz\"\n",
    "    raw_filename = f\"{raw_reads_dir}{sample}_R1_001.fastq.gz\"\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(raw_filename, 'rt') as raw:\n",
    "            raw_count = sum(1 for _ in raw)\n",
    "        \n",
    "        with gzip.open(trim_filename, 'rt') as trim:\n",
    "            trim_count = sum(1 for _ in trim)\n",
    "        \n",
    "        counts_df[sample] = trim_count / raw_count\n",
    "        print(f\"Sample: {sample}, Raw Reads: {raw_count}, Trimmed Reads: {trim_count}, Ratio: {trim_count/raw_count}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for sample: {sample}\")\n",
    "        \n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec780c5-677f-42bf-a972-8a40dbdcdd63",
   "metadata": {},
   "source": [
    "#### finding number of paired reads that aligned concordantly with bowtie2 alignment and the refseq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d838949-11a1-4ed2-9860-49910bfa91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBB-WBO-B21-CV, Concordant Alignments: 1987316\n",
      "Sample: 2018--BBB-WBV-B70-CV, Concordant Alignments: 1702318\n",
      "Sample: 2018--BBO-BBO-B16-CV, Concordant Alignments: 1504682\n",
      "Sample: 2018--BBO-BBY-B27-CV, Concordant Alignments: 963810\n",
      "Sample: 2018--BBO-WBO-B16-CV, Concordant Alignments: 2076074\n",
      "Sample: 2018--BBO-WBV-B64-CV, Concordant Alignments: 1812804\n",
      "Sample: 2018--BBR-BBB-B50-CV, Concordant Alignments: 859402\n",
      "Sample: 2018--BBR-BBG-B38-CV, Concordant Alignments: 1538688\n",
      "Sample: 2018--BBR-BBY-B26-CV, Concordant Alignments: 1451844\n",
      "Sample: 2018--BBY-WBG-B42-CV, Concordant Alignments: 492580\n",
      "Sample: 2018--BPO-BPO-O16-CV, Concordant Alignments: 202704\n",
      "Sample: 2018--BPR-BPG-O38-CV, Concordant Alignments: 958966\n",
      "Sample: 2018--BPR-BPR-O02-CV, Concordant Alignments: 231214\n",
      "Sample: 2018--BPY-BPG-O42-CV, Concordant Alignments: 123478\n",
      "Sample: 2018--BPY-BPY-O29-CV, Concordant Alignments: 358770\n",
      "Sample: 2018--WBB-WBV-W69-CV, Concordant Alignments: 1841576\n",
      "Sample: 2018--WBG-BBB-W56-CV, Concordant Alignments: 1631652\n",
      "Sample: 2018--WBG-WBG-W44-CV, Concordant Alignments: 346466\n",
      "Sample: 2018--WBO-BBR-W03-CV, Concordant Alignments: 122690\n",
      "Sample: 2018--WBO-WBV-W64-CV, Concordant Alignments: 1528096\n",
      "Sample: 2018--WBR-BBY-W25-CV, Concordant Alignments: 491730\n",
      "Sample: 2018--WBV-WBO-W23-CV, Concordant Alignments: 597972\n",
      "Sample: 2018--WBV-WBR-W12-CV, Concordant Alignments: 180442\n",
      "Sample: 2018--WBY-BBV-W65-CV, Concordant Alignments: 1464800\n",
      "Sample: 2018--WBY-BBY-W30-CV, Concordant Alignments: 849148\n",
      "Sample: 2018--WPB-BPG-G45-CV, Concordant Alignments: 864162\n",
      "Sample: 2018--WPO-BPO-G16-CV, Concordant Alignments: 550898\n",
      "Sample: 2018--WPO-BPY-G28-CV, Concordant Alignments: 289212\n",
      "Sample: 2018--WPR-BPY-G25-CV, Concordant Alignments: 893860\n",
      "Sample: 2018--WPV-BPR-G11-CV, Concordant Alignments: 152496\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing Bowtie2 output files for your samples\n",
    "input_dir = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/SAM_files/'\n",
    "\n",
    "# List of sample names (corresponding to your input files)\n",
    "sample_names=( \"2018--BBB-WBO-B21-CV\",\n",
    "\"2018--BBB-WBV-B70-CV\",\n",
    "\"2018--BBO-BBO-B16-CV\",\n",
    "\"2018--BBO-BBY-B27-CV\",\n",
    "\"2018--BBO-WBO-B16-CV\",\n",
    "\"2018--BBO-WBV-B64-CV\",\n",
    "\"2018--BBR-BBB-B50-CV\",\n",
    "\"2018--BBR-BBG-B38-CV\",\n",
    "\"2018--BBR-BBY-B26-CV\",\n",
    "\"2018--BBY-WBG-B42-CV\",\n",
    "\"2018--BPO-BPO-O16-CV\",\n",
    "\"2018--BPR-BPG-O38-CV\",\n",
    "\"2018--BPR-BPR-O02-CV\",\n",
    "\"2018--BPY-BPG-O42-CV\",\n",
    "\"2018--BPY-BPY-O29-CV\",\n",
    "\"2018--WBB-WBV-W69-CV\",\n",
    "\"2018--WBG-BBB-W56-CV\",\n",
    "\"2018--WBG-WBG-W44-CV\",\n",
    "\"2018--WBO-BBR-W03-CV\",\n",
    "\"2018--WBO-WBV-W64-CV\",\n",
    "\"2018--WBR-BBY-W25-CV\",\n",
    "\"2018--WBV-WBO-W23-CV\",\n",
    "\"2018--WBV-WBR-W12-CV\",\n",
    "\"2018--WBY-BBV-W65-CV\",\n",
    "\"2018--WBY-BBY-W30-CV\",\n",
    "\"2018--WPB-BPG-G45-CV\",\n",
    "\"2018--WPO-BPO-G16-CV\",\n",
    "\"2018--WPO-BPY-G28-CV\",\n",
    "\"2018--WPR-BPY-G25-CV\",\n",
    "\"2018--WPV-BPR-G11-CV\" )\n",
    "\n",
    "# Dictionary to store concordant alignment counts for each sample\n",
    "concordant_counts = {}\n",
    "\n",
    "# Iterate through the list of samples\n",
    "for sample in sample_names:\n",
    "    # Construct the Bowtie2 output file path for the sample\n",
    "    bowtie2_output_file = os.path.join(input_dir, f'{sample}_alignment.sam')  # Assuming you have SAM output files\n",
    "\n",
    "    # Initialize the count for this sample\n",
    "    concordant_counts[sample] = 0\n",
    "\n",
    "    # Open and read the Bowtie2 output file\n",
    "    with open(bowtie2_output_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('@'):\n",
    "                continue  # Skip header lines\n",
    "            fields = line.split('\\t')\n",
    "            if fields[1] == '99' or fields[1] == '147':\n",
    "                # Check for the YT flag (99 or 147 indicates concordant alignments)\n",
    "                if 'YT:Z:CP' in line:\n",
    "                    concordant_counts[sample] += 1\n",
    "\n",
    "# Print the concordant alignment counts for each sample\n",
    "for sample, count in concordant_counts.items():\n",
    "    print(f'Sample: {sample}, Concordant Alignments: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05750630-876a-4770-822e-b7cf8d9bb455",
   "metadata": {},
   "source": [
    "#### marked duplicates counts from picard tools\n",
    "still not working - returning values of 0 even though the files have numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28e4c3b2-f6f3-48c6-89a1-35acd7074769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBB-WBO-B21, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBB-WBV-B70, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBO-BBO-B16, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBO-BBY-B27, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBO-WBO-B16, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBO-WBV-B64, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBR-BBB-B50, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBR-BBG-B38, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBR-BBY-B26, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BBY-WBG-B42, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BPO-BPO-O16, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BPR-BPG-O38, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BPR-BPR-O02, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BPY-BPG-O42, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--BPY-BPY-O29, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBB-WBV-W69, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBG-BBB-W56, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBG-WBG-W44, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBO-BBR-W03, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBO-WBV-W64, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBR-BBY-W25, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBV-WBO-W23, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBV-WBR-W12, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBY-BBV-W65, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WBY-BBY-W30, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WPB-BPG-G45, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WPO-BPO-G16, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WPO-BPY-G28, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WPR-BPY-G25, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n",
      "Sample: 2018--WPV-BPR-G11, READ_PAIR_OPTICAL_DUPLICATES Counts: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing Picard Metrics files for your samples\n",
    "input_dir = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/mark_dups/mark_dups_metrics/'\n",
    "\n",
    "# List of sample names (corresponding to your input files)\n",
    "sample_names=( \"2018--BBB-WBO-B21\",\n",
    "\"2018--BBB-WBV-B70\",\n",
    "\"2018--BBO-BBO-B16\",\n",
    "\"2018--BBO-BBY-B27\",\n",
    "\"2018--BBO-WBO-B16\",\n",
    "\"2018--BBO-WBV-B64\",\n",
    "\"2018--BBR-BBB-B50\",\n",
    "\"2018--BBR-BBG-B38\",\n",
    "\"2018--BBR-BBY-B26\",\n",
    "\"2018--BBY-WBG-B42\",\n",
    "\"2018--BPO-BPO-O16\",\n",
    "\"2018--BPR-BPG-O38\",\n",
    "\"2018--BPR-BPR-O02\",\n",
    "\"2018--BPY-BPG-O42\",\n",
    "\"2018--BPY-BPY-O29\",\n",
    "\"2018--WBB-WBV-W69\",\n",
    "\"2018--WBG-BBB-W56\",\n",
    "\"2018--WBG-WBG-W44\",\n",
    "\"2018--WBO-BBR-W03\",\n",
    "\"2018--WBO-WBV-W64\",\n",
    "\"2018--WBR-BBY-W25\",\n",
    "\"2018--WBV-WBO-W23\",\n",
    "\"2018--WBV-WBR-W12\",\n",
    "\"2018--WBY-BBV-W65\",\n",
    "\"2018--WBY-BBY-W30\",\n",
    "\"2018--WPB-BPG-G45\",\n",
    "\"2018--WPO-BPO-G16\",\n",
    "\"2018--WPO-BPY-G28\",\n",
    "\"2018--WPR-BPY-G25\",\n",
    "\"2018--WPV-BPR-G11\" )\n",
    "\n",
    "# Dictionary to store READ_PAIR_OPTICAL_DUPLICATES counts for each sample\n",
    "optical_duplicate_counts = {}\n",
    "\n",
    "# Iterate through the list of samples\n",
    "for sample in sample_names:\n",
    "    # Construct the Picard Metrics file path for the sample\n",
    "    picard_metrics_file = os.path.join(input_dir, f'{sample}-marked_dup_metrics.txt')\n",
    "\n",
    "    # Initialize the count for this sample\n",
    "    optical_duplicate_counts[sample] = 0\n",
    "\n",
    "    # Open and read the Picard Metrics file\n",
    "    with open(picard_metrics_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('READ_PAIR_OPTICAL_DUPLICATES'):\n",
    "                try:\n",
    "                    # Extract the value after the last tab and convert to integer\n",
    "                    optical_duplicate_counts[sample] = int(line.split('\\t')[-3].strip())\n",
    "                except ValueError:\n",
    "                    print(f\"Skipping non-numeric value for {sample}\")\n",
    "                    break  # Stop reading further lines for this sample\n",
    "\n",
    "# Print the optical duplicate counts for each sample\n",
    "for sample, count in optical_duplicate_counts.items():\n",
    "    print(f'Sample: {sample}, READ_PAIR_OPTICAL_DUPLICATES Counts: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2b840-ddd8-48eb-b98e-7213462fdf6f",
   "metadata": {},
   "source": [
    "### checking if our reads actually have a methyl group in the middle\n",
    "enzyme: FspEI https://www.neb.com/en-us/products/r0662-fspei#Product%20Information\n",
    "\n",
    "At fully methylated CpG sites: \n",
    "5´. . . C mC  G G . . . 3´\n",
    "3´. . . G  G mC C . . . 5´\n",
    "\n",
    "or CHG sites: \n",
    "5´. . . C mC H  G G . . . 3´\n",
    "3´. . . G  G D mC C . . . 5´\n",
    "\n",
    "H = A or C or T (not G)\n",
    "D = A or G or T (not C) \n",
    "\n",
    "so need to check how many reads have that fully methylated CpG site pattern in the middle of CHG site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a0f1c0-6fc5-465c-b4ba-3f1432165259",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(zip_file_name)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m sample_counts[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Initialize count to 0\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipped_samples_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_file:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mnamelist():\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mopen(file_name) \u001b[38;5;28;01mas\u001b[39;00m sample_file:\n",
      "File \u001b[0;32m/modules/apps/ood/jupyterlab/lib/python3.11/zipfile.py:1299\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1299\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/modules/apps/ood/jupyterlab/lib/python3.11/zipfile.py:1366\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Directory containing your zipped sample files\n",
    "zipped_samples_dir = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files'\n",
    "\n",
    "# Specific sequence you want to search for\n",
    "target_sequence = ['CCAGG','CCCGG','CCTGG']\n",
    "\n",
    "# Dictionary to store counts for each sample\n",
    "sample_counts = {}\n",
    "\n",
    "# Loop through the zipped sample files\n",
    "for zip_file_name in os.listdir(zipped_samples_dir):\n",
    "    if zip_file_name.endswith('R1_001_val_1.fq.gz'):\n",
    "        sample_name = os.path.splitext(zip_file_name)[0]\n",
    "        sample_counts[sample_name] = 0  # Initialize count to 0\n",
    "\n",
    "        with zipfile.ZipFile(os.path.join(zipped_samples_dir, zip_file_name), 'r') as zip_file:\n",
    "            for file_name in zip_file.namelist():\n",
    "                with zip_file.open(file_name) as sample_file:\n",
    "                    for line in sample_file:\n",
    "                        line = line.decode('utf-8')  # Decode the line if needed\n",
    "                        if target_sequence in line:\n",
    "                            sample_counts[sample_name] += 1\n",
    "\n",
    "# Print the counts for each sample\n",
    "for sample_name, count in sample_counts.items():\n",
    "    print(f\"Sample: {sample_name}, Count: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d86a8-394e-455a-b5a9-b3f7d11a7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "list_yes = []\n",
    "\n",
    "s = \"ACGTATCGAAGACGT\"\n",
    "forward = ['CCAGG','CCCGG','CCTGG']\n",
    "reverse = ['GGACC','GGGCC','GGTCC']\n",
    "\n",
    "result = re.findall(r'ATCGAAG', forward)\n",
    "\n",
    "if result:\n",
    "    list_yes.append(i)\n",
    "else:\n",
    "    print(\"The pattern 'ATCGAAG' is not in the middle of the reads.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
