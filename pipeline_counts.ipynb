{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c45096cb-0746-4761-84f4-f08cc4c9f798",
   "metadata": {},
   "source": [
    "## Pipeline Counts for methylRAD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41ef22-29c3-4dcc-af96-6cd25a229aae",
   "metadata": {},
   "source": [
    "#### counts of raw reads and trimmed reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bfe304-31d2-492a-8115-e64f1f67484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing package to move through directories\n",
    "import os\n",
    "# to change directory\n",
    "os.chdir(\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d849e4-a444-4e30-9b76-47b45c3259a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBO-WBO-B16-CV, Raw Reads: 59769484, Trimmed Reads: 9603844, Ratio: 0.1606813938698216\n",
      "Sample: 2018--BPO-BPO-O16-CV, Raw Reads: 17002472, Trimmed Reads: 936764, Ratio: 0.05509575313519117\n",
      "Sample: 2018--WBV-WBO-W23-CV, Raw Reads: 20244836, Trimmed Reads: 2744600, Ratio: 0.13557037458836416\n",
      "Sample: 2018--BPR-BPG-O38-CV, Raw Reads: 38746892, Trimmed Reads: 4390176, Ratio: 0.11330395222409065\n",
      "Sample: 2018--BBO-WBV-B64-CV, Raw Reads: 49958272, Trimmed Reads: 8379816, Ratio: 0.167736306011545\n",
      "Sample: 2018--WBB-WBV-W69-CV, Raw Reads: 41913360, Trimmed Reads: 8547732, Ratio: 0.20393812378678303\n",
      "Sample: 2018--WPO-BPY-G28-CV, Raw Reads: 26339844, Trimmed Reads: 1346688, Ratio: 0.05112740986620878\n",
      "Sample: 2018--WPB-BPG-G45-CV, Raw Reads: 38780388, Trimmed Reads: 4035068, Ratio: 0.10404919104986779\n",
      "Sample: 2018--BBB-WBV-B70-CV, Raw Reads: 47021020, Trimmed Reads: 7920020, Ratio: 0.16843573363572292\n",
      "Sample: 2018--BBB-WBO-B21-CV, Raw Reads: 60015908, Trimmed Reads: 9142520, Ratio: 0.15233494426177807\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from Bio import SeqIO\n",
    "\n",
    "# read directories\n",
    "raw_reads_dir = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/Raw_sequences/methyl_raw/\"\n",
    "trimmed_reads_dir = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files/\"\n",
    "\n",
    "# Collect unique sample names from raw reads directory\n",
    "sample_names = set()\n",
    "for filename in os.listdir(raw_reads_dir):\n",
    "    if filename.endswith(\".fastq.gz\"):\n",
    "        sample_name = filename.split(\"_\")[0]\n",
    "        sample_names.add(sample_name)\n",
    "\n",
    "counts_df = {}\n",
    "# Count reads for each unique sample\n",
    "for sample in sample_names:\n",
    "    trim_filename = f\"{trimmed_reads_dir}{sample}_R1_001_val_1.fq.gz\"\n",
    "    raw_filename = f\"{raw_reads_dir}{sample}_R1_001.fastq.gz\"\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(raw_filename, 'rt') as raw:\n",
    "            raw_count = sum(1 for _ in raw)\n",
    "        \n",
    "        with gzip.open(trim_filename, 'rt') as trim:\n",
    "            trim_count = sum(1 for _ in trim)\n",
    "        \n",
    "        counts_df[sample] = trim_count / raw_count\n",
    "        print(f\"Sample: {sample}, Raw Reads: {raw_count}, Trimmed Reads: {trim_count}, Ratio: {trim_count/raw_count}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for sample: {sample}\")\n",
    "        \n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec780c5-677f-42bf-a972-8a40dbdcdd63",
   "metadata": {},
   "source": [
    "#### finding number of paired reads that aligned concordantly with bowtie2 alignment and the refseq "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d838949-11a1-4ed2-9860-49910bfa91d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBB-WBO-B21-CV, Concordant Alignments: 1987316\n",
      "Sample: 2018--BBB-WBV-B70-CV, Concordant Alignments: 1702318\n",
      "Sample: 2018--BBO-BBO-B16-CV, Concordant Alignments: 1504682\n",
      "Sample: 2018--BBO-BBY-B27-CV, Concordant Alignments: 963810\n",
      "Sample: 2018--BBO-WBO-B16-CV, Concordant Alignments: 2076074\n",
      "Sample: 2018--BBO-WBV-B64-CV, Concordant Alignments: 1812804\n",
      "Sample: 2018--BBR-BBB-B50-CV, Concordant Alignments: 859402\n",
      "Sample: 2018--BBR-BBG-B38-CV, Concordant Alignments: 1538688\n",
      "Sample: 2018--BBR-BBY-B26-CV, Concordant Alignments: 1451844\n",
      "Sample: 2018--BBY-WBG-B42-CV, Concordant Alignments: 492580\n",
      "Sample: 2018--BPO-BPO-O16-CV, Concordant Alignments: 202704\n",
      "Sample: 2018--BPR-BPG-O38-CV, Concordant Alignments: 958966\n",
      "Sample: 2018--BPR-BPR-O02-CV, Concordant Alignments: 231214\n",
      "Sample: 2018--BPY-BPG-O42-CV, Concordant Alignments: 123478\n",
      "Sample: 2018--BPY-BPY-O29-CV, Concordant Alignments: 358770\n",
      "Sample: 2018--WBB-WBV-W69-CV, Concordant Alignments: 1841576\n",
      "Sample: 2018--WBG-BBB-W56-CV, Concordant Alignments: 1631652\n",
      "Sample: 2018--WBG-WBG-W44-CV, Concordant Alignments: 346466\n",
      "Sample: 2018--WBO-BBR-W03-CV, Concordant Alignments: 122690\n",
      "Sample: 2018--WBO-WBV-W64-CV, Concordant Alignments: 1528096\n",
      "Sample: 2018--WBR-BBY-W25-CV, Concordant Alignments: 491730\n",
      "Sample: 2018--WBV-WBO-W23-CV, Concordant Alignments: 597972\n",
      "Sample: 2018--WBV-WBR-W12-CV, Concordant Alignments: 180442\n",
      "Sample: 2018--WBY-BBV-W65-CV, Concordant Alignments: 1464800\n",
      "Sample: 2018--WBY-BBY-W30-CV, Concordant Alignments: 849148\n",
      "Sample: 2018--WPB-BPG-G45-CV, Concordant Alignments: 864162\n",
      "Sample: 2018--WPO-BPO-G16-CV, Concordant Alignments: 550898\n",
      "Sample: 2018--WPO-BPY-G28-CV, Concordant Alignments: 289212\n",
      "Sample: 2018--WPR-BPY-G25-CV, Concordant Alignments: 893860\n",
      "Sample: 2018--WPV-BPR-G11-CV, Concordant Alignments: 152496\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Directory containing Bowtie2 output files for your samples\n",
    "input_dir = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/SAM_files/'\n",
    "\n",
    "# List of sample names (corresponding to your input files)\n",
    "sample_names=( \"2018--BBB-WBO-B21-CV\",\n",
    "\"2018--BBB-WBV-B70-CV\",\n",
    "\"2018--BBO-BBO-B16-CV\",\n",
    "\"2018--BBO-BBY-B27-CV\",\n",
    "\"2018--BBO-WBO-B16-CV\",\n",
    "\"2018--BBO-WBV-B64-CV\",\n",
    "\"2018--BBR-BBB-B50-CV\",\n",
    "\"2018--BBR-BBG-B38-CV\",\n",
    "\"2018--BBR-BBY-B26-CV\",\n",
    "\"2018--BBY-WBG-B42-CV\",\n",
    "\"2018--BPO-BPO-O16-CV\",\n",
    "\"2018--BPR-BPG-O38-CV\",\n",
    "\"2018--BPR-BPR-O02-CV\",\n",
    "\"2018--BPY-BPG-O42-CV\",\n",
    "\"2018--BPY-BPY-O29-CV\",\n",
    "\"2018--WBB-WBV-W69-CV\",\n",
    "\"2018--WBG-BBB-W56-CV\",\n",
    "\"2018--WBG-WBG-W44-CV\",\n",
    "\"2018--WBO-BBR-W03-CV\",\n",
    "\"2018--WBO-WBV-W64-CV\",\n",
    "\"2018--WBR-BBY-W25-CV\",\n",
    "\"2018--WBV-WBO-W23-CV\",\n",
    "\"2018--WBV-WBR-W12-CV\",\n",
    "\"2018--WBY-BBV-W65-CV\",\n",
    "\"2018--WBY-BBY-W30-CV\",\n",
    "\"2018--WPB-BPG-G45-CV\",\n",
    "\"2018--WPO-BPO-G16-CV\",\n",
    "\"2018--WPO-BPY-G28-CV\",\n",
    "\"2018--WPR-BPY-G25-CV\",\n",
    "\"2018--WPV-BPR-G11-CV\" )\n",
    "\n",
    "# Dictionary to store concordant alignment counts for each sample\n",
    "concordant_counts = {}\n",
    "\n",
    "# Iterate through the list of samples\n",
    "for sample in sample_names:\n",
    "    # Construct the Bowtie2 output file path for the sample\n",
    "    bowtie2_output_file = os.path.join(input_dir, f'{sample}_alignment.sam')  # Assuming you have SAM output files\n",
    "\n",
    "    # Initialize the count for this sample\n",
    "    concordant_counts[sample] = 0\n",
    "\n",
    "    # Open and read the Bowtie2 output file\n",
    "    with open(bowtie2_output_file, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('@'):\n",
    "                continue  # Skip header lines\n",
    "            fields = line.split('\\t')\n",
    "            if fields[1] == '99' or fields[1] == '147':\n",
    "                # Check for the YT flag (99 or 147 indicates concordant alignments)\n",
    "                if 'YT:Z:CP' in line:\n",
    "                    concordant_counts[sample] += 1\n",
    "\n",
    "# Print the concordant alignment counts for each sample\n",
    "for sample, count in concordant_counts.items():\n",
    "    print(f'Sample: {sample}, Concordant Alignments: {count}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05750630-876a-4770-822e-b7cf8d9bb455",
   "metadata": {},
   "source": [
    "#### marked duplicates counts from picard tools\n",
    "returns paired reads, unpaired reads, and read pair optical duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6581c716-bc3b-4c7b-976d-c008de239c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpe: 2020021 ure: 14421 rpod: 9850\n"
     ]
    }
   ],
   "source": [
    "# base code for one file\n",
    "metrics_file = pd.read_csv(\"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/mark_dups/mark_dups_metrics/2018--BBB-WBO-B21-marked_dup_metrics.txt\")\n",
    "metrics_file.head(10)\n",
    "\n",
    "metrics_file.index == 5\n",
    "metrics_file[metrics_file.index == 5]\n",
    "\n",
    "header_row_values = metrics_file['## htsjdk.samtools.metrics.StringHeader'].str.split('\\t', expand=True)\n",
    "header_row_values.head(6)\n",
    "\n",
    "\n",
    "header_row_values.columns = header_row_values.iloc[4]\n",
    "df = pd.DataFrame(header_row_values.iloc[5, :])\n",
    "df = df.transpose().reset_index()\n",
    "rpe = df['READ_PAIRS_EXAMINED'][0]\n",
    "ure = df['UNPAIRED_READS_EXAMINED'][0]\n",
    "rpod = df['READ_PAIR_OPTICAL_DUPLICATES'][0]\n",
    "\n",
    "print('rpe:', rpe, 'ure:', ure, 'rpod:', rpod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7e44347-511b-46e4-b56a-177a2847d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 2018--BBB-WBO-B21, Paired Reads: 2020021, Unpaired Reads: 14421, Optical Duplicates: 9850\n",
      "Sample: 2018--BBB-WBV-B70, Paired Reads: 1733903, Unpaired Reads: 12637, Optical Duplicates: 9107\n",
      "Sample: 2018--BBO-BBO-B16, Paired Reads: 1527667, Unpaired Reads: 11081, Optical Duplicates: 4699\n",
      "Sample: 2018--BBO-BBY-B27, Paired Reads: 978519, Unpaired Reads: 6871, Optical Duplicates: 3552\n",
      "Sample: 2018--BBO-WBO-B16, Paired Reads: 2109689, Unpaired Reads: 14556, Optical Duplicates: 10334\n",
      "Sample: 2018--BBO-WBV-B64, Paired Reads: 1840935, Unpaired Reads: 13313, Optical Duplicates: 8994\n",
      "Sample: 2018--BBR-BBB-B50, Paired Reads: 874456, Unpaired Reads: 6878, Optical Duplicates: 2652\n",
      "Sample: 2018--BBR-BBG-B38, Paired Reads: 1562707, Unpaired Reads: 11822, Optical Duplicates: 5177\n",
      "Sample: 2018--BBR-BBY-B26, Paired Reads: 1476603, Unpaired Reads: 11046, Optical Duplicates: 4909\n",
      "Sample: 2018--BBY-WBG-B42, Paired Reads: 501016, Unpaired Reads: 4711, Optical Duplicates: 1523\n",
      "Sample: 2018--BPO-BPO-O16, Paired Reads: 205884, Unpaired Reads: 2178, Optical Duplicates: 395\n",
      "Sample: 2018--BPR-BPG-O38, Paired Reads: 970743, Unpaired Reads: 7173, Optical Duplicates: 3386\n",
      "Sample: 2018--BPR-BPR-O02, Paired Reads: 235712, Unpaired Reads: 2447, Optical Duplicates: 616\n",
      "Sample: 2018--BPY-BPG-O42, Paired Reads: 125939, Unpaired Reads: 1464, Optical Duplicates: 243\n",
      "Sample: 2018--BPY-BPY-O29, Paired Reads: 365572, Unpaired Reads: 3414, Optical Duplicates: 1033\n",
      "Sample: 2018--WBB-WBV-W69, Paired Reads: 1866682, Unpaired Reads: 14635, Optical Duplicates: 8793\n",
      "Sample: 2018--WBG-BBB-W56, Paired Reads: 1660416, Unpaired Reads: 13827, Optical Duplicates: 7376\n",
      "Sample: 2018--WBG-WBG-W44, Paired Reads: 351751, Unpaired Reads: 3415, Optical Duplicates: 973\n",
      "Sample: 2018--WBO-BBR-W03, Paired Reads: 124954, Unpaired Reads: 1941, Optical Duplicates: 157\n",
      "Sample: 2018--WBO-WBV-W64, Paired Reads: 1554342, Unpaired Reads: 11155, Optical Duplicates: 7532\n",
      "Sample: 2018--WBR-BBY-W25, Paired Reads: 501023, Unpaired Reads: 4560, Optical Duplicates: 1947\n",
      "Sample: 2018--WBV-WBO-W23, Paired Reads: 605699, Unpaired Reads: 5243, Optical Duplicates: 2083\n",
      "Sample: 2018--WBV-WBR-W12, Paired Reads: 183009, Unpaired Reads: 1604, Optical Duplicates: 520\n",
      "Sample: 2018--WBY-BBV-W65, Paired Reads: 1488899, Unpaired Reads: 12069, Optical Duplicates: 6248\n",
      "Sample: 2018--WBY-BBY-W30, Paired Reads: 862643, Unpaired Reads: 7540, Optical Duplicates: 3542\n",
      "Sample: 2018--WPB-BPG-G45, Paired Reads: 876722, Unpaired Reads: 6833, Optical Duplicates: 2418\n",
      "Sample: 2018--WPO-BPO-G16, Paired Reads: 560687, Unpaired Reads: 4805, Optical Duplicates: 1476\n",
      "Sample: 2018--WPO-BPY-G28, Paired Reads: 292644, Unpaired Reads: 2711, Optical Duplicates: 1024\n",
      "Sample: 2018--WPR-BPY-G25, Paired Reads: 910353, Unpaired Reads: 7902, Optical Duplicates: 3422\n",
      "Sample: 2018--WPV-BPR-G11, Paired Reads: 156427, Unpaired Reads: 1302, Optical Duplicates: 541\n"
     ]
    }
   ],
   "source": [
    "# same code but adapted to loop through all files\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set the path to the directory containing your Picard metrics files\n",
    "input_directory = \"/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/assembly/bowtie2_refseq/mark_dups/mark_dups_metrics\"\n",
    "\n",
    "# List of sample names (corresponding to your input files)\n",
    "sample_names=['2018--BBB-WBO-B21', '2018--BBB-WBV-B70', \n",
    "              '2018--BBO-BBO-B16', '2018--BBO-BBY-B27', \n",
    "              '2018--BBO-WBO-B16', '2018--BBO-WBV-B64', \n",
    "              '2018--BBR-BBB-B50', '2018--BBR-BBG-B38', \n",
    "              '2018--BBR-BBY-B26', '2018--BBY-WBG-B42', \n",
    "              '2018--BPO-BPO-O16', '2018--BPR-BPG-O38', \n",
    "              '2018--BPR-BPR-O02', '2018--BPY-BPG-O42', \n",
    "              '2018--BPY-BPY-O29', '2018--WBB-WBV-W69', \n",
    "              '2018--WBG-BBB-W56', '2018--WBG-WBG-W44', \n",
    "              '2018--WBO-BBR-W03', '2018--WBO-WBV-W64', \n",
    "              '2018--WBR-BBY-W25', '2018--WBV-WBO-W23', \n",
    "              '2018--WBV-WBR-W12', '2018--WBY-BBV-W65', \n",
    "              '2018--WBY-BBY-W30', '2018--WPB-BPG-G45', \n",
    "              '2018--WPO-BPO-G16', '2018--WPO-BPY-G28', \n",
    "              '2018--WPR-BPY-G25', '2018--WPV-BPR-G11']\n",
    "\n",
    "\n",
    "# Initialize variables to store metrics values\n",
    "upe = 0\n",
    "rpe = 0\n",
    "rpod = 0\n",
    "\n",
    "# Loop through each sample name\n",
    "for sample in sample_names:\n",
    "    # Construct the metrics file path for the current sample\n",
    "    file = f\"{sample}-marked_dup_metrics.txt\"\n",
    "    metrics_file_path = os.path.join(input_directory, file)\n",
    "\n",
    "    # Read the metrics file for the current sample\n",
    "    metrics_file = pd.read_csv(metrics_file_path, sep='\\t', skiprows=6, nrows=1)\n",
    "\n",
    "    # Extract relevant metrics\n",
    "    rpe = metrics_file['READ_PAIRS_EXAMINED'].values[0]\n",
    "    ure = metrics_file['UNPAIRED_READS_EXAMINED'].values[0]\n",
    "    rpod = metrics_file['READ_PAIR_OPTICAL_DUPLICATES'].values[0]\n",
    "\n",
    "    # Print or use the information as needed for each sample\n",
    "    print(f\"Sample: {sample}, Paired Reads: {rpe}, Unpaired Reads: {ure}, Optical Duplicates: {rpod}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2b840-ddd8-48eb-b98e-7213462fdf6f",
   "metadata": {},
   "source": [
    "### checking if our reads actually have a methyl group in the middle\n",
    "enzyme: FspEI https://www.neb.com/en-us/products/r0662-fspei#Product%20Information\n",
    "\n",
    "At fully methylated CpG sites: \n",
    "5´. . . C mC  G G . . . 3´\n",
    "3´. . . G  G mC C . . . 5´\n",
    "\n",
    "or CHG sites: \n",
    "5´. . . C mC H  G G . . . 3´\n",
    "3´. . . G  G D mC C . . . 5´\n",
    "\n",
    "H = A or C or T (not G)\n",
    "D = A or G or T (not C) \n",
    "\n",
    "so need to check how many reads have that fully methylated CpG site pattern in the middle of CHG site "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a0f1c0-6fc5-465c-b4ba-3f1432165259",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m sample_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(zip_file_name)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m sample_counts[sample_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Initialize count to 0\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipped_samples_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzip_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_file:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mnamelist():\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m zip_file\u001b[38;5;241m.\u001b[39mopen(file_name) \u001b[38;5;28;01mas\u001b[39;00m sample_file:\n",
      "File \u001b[0;32m/modules/apps/ood/jupyterlab/lib/python3.11/zipfile.py:1299\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1299\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1301\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/modules/apps/ood/jupyterlab/lib/python3.11/zipfile.py:1366\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1368\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Directory containing your zipped sample files\n",
    "zipped_samples_dir = '/project/pi_sarah_gignouxwolfsohn_uml_edu/julia/trimmed/filtered_auto_trim_sequences/trim_files'\n",
    "\n",
    "# Specific sequence you want to search for\n",
    "target_sequence = ['CCAGG','CCCGG','CCTGG']\n",
    "\n",
    "# Dictionary to store counts for each sample\n",
    "sample_counts = {}\n",
    "\n",
    "# Loop through the zipped sample files\n",
    "for zip_file_name in os.listdir(zipped_samples_dir):\n",
    "    if zip_file_name.endswith('R1_001_val_1.fq.gz'):\n",
    "        sample_name = os.path.splitext(zip_file_name)[0]\n",
    "        sample_counts[sample_name] = 0  # Initialize count to 0\n",
    "\n",
    "        with zipfile.ZipFile(os.path.join(zipped_samples_dir, zip_file_name), 'r') as zip_file:\n",
    "            for file_name in zip_file.namelist():\n",
    "                with zip_file.open(file_name) as sample_file:\n",
    "                    for line in sample_file:\n",
    "                        line = line.decode('utf-8')  # Decode the line if needed\n",
    "                        if target_sequence in line:\n",
    "                            sample_counts[sample_name] += 1\n",
    "\n",
    "# Print the counts for each sample\n",
    "for sample_name, count in sample_counts.items():\n",
    "    print(f\"Sample: {sample_name}, Count: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67d86a8-394e-455a-b5a9-b3f7d11a7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "list_yes = []\n",
    "\n",
    "s = \"ACGTATCGAAGACGT\"\n",
    "forward = ['CCAGG','CCCGG','CCTGG']\n",
    "reverse = ['GGACC','GGGCC','GGTCC']\n",
    "\n",
    "result = re.findall(r'ATCGAAG', forward)\n",
    "\n",
    "if result:\n",
    "    list_yes.append(i)\n",
    "else:\n",
    "    print(\"The pattern 'ATCGAAG' is not in the middle of the reads.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
